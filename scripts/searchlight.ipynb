{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searchlight Analysis\n",
    "Searchlight Analysis is used to sequentially analyze small groups of voxels in the brain in order to identify regions of interest. The technique is designed in the following steps:\n",
    "\n",
    "1. Define a sphere of voxels around a seed voxel\n",
    "2. Extract the time series from each voxel in the sphere\n",
    "3. Concatenate the time series into a feature vector\n",
    "4. Train a classifier on the feature vector and the labels\n",
    "5. Use the classifier to predict the labels of the seed voxel\n",
    "6. Repeat steps 1-5 for all seed voxels\n",
    "7. Aggregate the results across all seed voxels to form a statistical map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "\n",
    "from preprocessing import load_cleaned_data\n",
    "cleaned_data_audio, cleaned_data_visual = load_cleaned_data()\n",
    "\n",
    "# Convert 4D fMRI to a 2D array (samples per timepoint x features)\n",
    "audio_data = cleaned_data_audio.get_fdata()\n",
    "visual_data = cleaned_data_visual.get_fdata()\n",
    "\n",
    "# Reshape data: (x, y, z, time) -> (time, x*y*z)\n",
    "X_audio = audio_data.reshape(audio_data.shape[-1], -1)\n",
    "X_visual = visual_data.reshape(visual_data.shape[-1], -1)\n",
    "\n",
    "# Create labels (0 for audio, 1 for visual)\n",
    "y_audio = np.zeros(X_audio.shape[0])\n",
    "y_visual = np.ones(X_visual.shape[0])\n",
    "\n",
    "# combine datasets to create a single feature matrix and labels\n",
    "X = np.vstack((X_audio, X_visual))\n",
    "y = np.hstack((y_audio, y_visual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Set up Linear SVM classifier and train the new feature matrix\n",
    "\n",
    "\n",
    "# Set up model pipeline\n",
    "pipeline = make_pipeline(StandardScaler(), LinearSVC( random_state = 42, tol = 1e-4, C = 1.0, max_iter = 2000))\n",
    "pipeline = Pipeline(steps = [('standardscaler', StandardScaler()),\n",
    "                ('linearsvc', LinearSVC(random_state=0, tol=1e-05))])\n",
    "\n",
    "# set up features\n",
    "n_voxels = 1000\n",
    "X, y = make_classification(n_features=n_voxels, random_state=42)\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Test print the model score\n",
    "print(pipeline.score(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
